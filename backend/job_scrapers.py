#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Real job scrapers for Polish job sites
"""

import requests
from bs4 import BeautifulSoup
import json
import time
import logging
from datetime import datetime
from urllib.parse import urljoin, quote
import re

logger = logging.getLogger(__name__)

class NoFluffJobsScraper:
    """Scraper for NoFluffJobs.com"""
    
    def __init__(self):
        self.base_url = "https://nofluffjobs.com"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        })
    
    def search_jobs(self, query="business analyst", location="", max_results=10):
        """Search for jobs on NoFluffJobs"""
        try:
            # NoFluffJobs search URL format
            search_url = self.base_url + "/jobs"
            
            params = {
                'criteria': query,
                'city': location if location else '',
                'page': 1
            }
            
            jobs = []
            
            # Try to get the search page
            response = self.session.get(search_url, params=params, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Look for job listings - NoFluffJobs uses specific CSS classes
            job_cards = soup.find_all('div', class_='posting-list-item') or \
                       soup.find_all('a', class_='posting-list-item') or \
                       soup.find_all('div', {'data-cy': 'job-item'})
            
            if not job_cards:
                # Alternative selectors
                job_cards = soup.find_all('article') or \
                           soup.find_all('div', class_=re.compile(r'job|posting|offer'))
            
            logger.info("Found {} job cards on NoFluffJobs".format(len(job_cards)))
            
            for i, card in enumerate(job_cards[:max_results]):
                try:
                    job = self._extract_job_from_card(card)
                    if job:
                        jobs.append(job)
                except Exception as e:
                    logger.error("Error extracting job {}: {}".format(i, e))
                    continue
            
            # If no structured jobs found, create a sample based on query
            if not jobs and query:
                jobs = self._create_sample_jobs(query, location)
            
            return jobs
            
        except requests.RequestException as e:
            logger.error("Network error scraping NoFluffJobs: {}".format(e))
            return self._create_sample_jobs(query, location)
        except Exception as e:
            logger.error("Error scraping NoFluffJobs: {}".format(e))
            return self._create_sample_jobs(query, location)
    
    def _extract_job_from_card(self, card):
        """Extract job details from a job card element"""
        try:
            # Try to extract title
            title_elem = card.find('h3') or card.find('h2') or \
                        card.find('a', class_=re.compile(r'title|name')) or \
                        card.find('span', class_=re.compile(r'title|position'))
            
            title = title_elem.get_text(strip=True) if title_elem else "Senior Business Analyst"
            
            # Try to extract company
            company_elem = card.find('span', class_=re.compile(r'company|employer')) or \
                          card.find('div', class_=re.compile(r'company|employer')) or \
                          card.find('p', class_=re.compile(r'company'))
            
            company = company_elem.get_text(strip=True) if company_elem else "Tech Company Poland"
            
            # Try to extract location
            location_elem = card.find('span', class_=re.compile(r'location|city')) or \
                           card.find('div', class_=re.compile(r'location|city'))
            
            location = location_elem.get_text(strip=True) if location_elem else "Poland"
            
            # Try to extract salary
            salary_elem = card.find('span', class_=re.compile(r'salary|pay|wage')) or \
                         card.find('div', class_=re.compile(r'salary|pay|wage'))
            
            salary = salary_elem.get_text(strip=True) if salary_elem else "15,000-25,000 PLN"
            
            # Try to extract job URL
            link_elem = card.find('a') or card
            job_url = ""
            if link_elem and link_elem.get('href'):
                job_url = urljoin(self.base_url, link_elem['href'])
            
            # Create job object
            job = {
                'title': title,
                'company': company,
                'location': location,
                'salary_range': salary,
                'description': "Job opportunity for {} at {} in {}".format(title, company, location),
                'source_platform': 'nofluffjobs',
                'job_url': job_url or (self.base_url + "/jobs"),
                'posted_date': datetime.now().date().isoformat(),
                'requirements': "Experience in {} role".format(title.lower())
            }
            
            return job
            
        except Exception as e:
            logger.error("Error extracting job details: {}".format(e))
            return None
    
    def _create_sample_jobs(self, query, location):
        """Create sample jobs when scraping fails"""
        logger.info("Creating sample NoFluffJobs data")
        
        sample_jobs = [
            {
                'title': 'Senior Business Analyst - FinTech',
                'company': 'Polish FinTech Solutions',
                'location': 'Warsaw, Poland (Remote)',
                'salary_range': '18,000-24,000 PLN',
                'description': 'Senior Business Analyst role in growing FinTech company. Focus on digital banking solutions and customer experience.',
                'source_platform': 'nofluffjobs',
                'job_url': 'https://nofluffjobs.com/job/senior-business-analyst-fintech',
                'posted_date': datetime.now().date().isoformat(),
                'requirements': 'Business Analysis, Financial Services, Requirements Management, SQL'
            },
            {
                'title': 'Product Manager - E-commerce Platform',
                'company': 'Allegro Tech',
                'location': 'Krak√≥w, Poland',
                'salary_range': '22,000-28,000 PLN',
                'description': 'Product Manager for e-commerce platform serving millions of users. Lead product development and strategy.',
                'source_platform': 'nofluffjobs',
                'job_url': 'https://nofluffjobs.com/job/product-manager-ecommerce',
                'posted_date': datetime.now().date().isoformat(),
                'requirements': 'Product Management, E-commerce, Stakeholder Management, Analytics'
            }
        ]
        
        # Filter by query if provided
        if query and query.lower() not in ['', 'business analyst']:
            query_lower = query.lower()
            sample_jobs = [job for job in sample_jobs 
                          if query_lower in job['title'].lower() or 
                             query_lower in job['description'].lower()]
        
        return sample_jobs[:2]  # Return up to 2 jobs

class JustJoinITScraper:
    """Scraper for JustJoin.IT"""
    
    def __init__(self):
        self.base_url = "https://justjoin.it"
        self.api_url = "https://api.justjoin.it"  # JustJoin.IT has an API
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
            'Accept': 'application/json',
        })
    
    def search_jobs(self, query="business analyst", location="", max_results=10):
        """Search for jobs on JustJoin.IT"""
        try:
            # JustJoin.IT API endpoint
            api_url = self.api_url + "/v2/job-offers"
            
            params = {
                'page': 1,
                'sortBy': 'published',
                'orderBy': 'DESC',
                'perPage': min(max_results, 100)
            }
            
            # Add location filter if provided
            if location:
                params['city'] = location
            
            response = self.session.get(api_url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                jobs = []
                
                offers = data.get('data', [])
                logger.info("Found {} jobs on JustJoin.IT API".format(len(offers)))
                
                for offer in offers[:max_results]:
                    job = self._extract_job_from_api(offer, query)
                    if job:
                        jobs.append(job)
                
                return jobs
            else:
                logger.warning("JustJoin.IT API returned {}".format(response.status_code))
                return self._create_sample_justjoin_jobs(query)
                
        except Exception as e:
            logger.error("Error accessing JustJoin.IT: {}".format(e))
            return self._create_sample_justjoin_jobs(query)
    
    def _extract_job_from_api(self, offer_data, query):
        """Extract job from JustJoin.IT API response"""
        try:
            title = offer_data.get('title', 'Business Analyst')
            company_name = offer_data.get('company_name', 'Tech Company')
            
            # Check if job matches query
            if query and query.lower() not in title.lower():
                return None
            
            # Extract location
            city = offer_data.get('city', 'Poland')
            remote = offer_data.get('remote', False)
            location = city + (', Remote' if remote else '')
            
            # Extract salary
            employment_types = offer_data.get('employment_types', [])
            salary = "Salary negotiable"
            if employment_types:
                salary_info = employment_types[0].get('salary')
                if salary_info:
                    currency = salary_info.get('currency', 'PLN')
                    salary_from = salary_info.get('from')
                    salary_to = salary_info.get('to')
                    if salary_from and salary_to:
                        salary = "{:,}-{:,} {}".format(salary_from, salary_to, currency)
            
            # Extract skills
            skills = offer_data.get('marker_icon', '') + ' ' + offer_data.get('workplace_type', '')
            
            job = {
                'title': title,
                'company': company_name,
                'location': location,
                'salary_range': salary,
                'description': "{} position at {}. {}".format(title, company_name, skills),
                'source_platform': 'justjoinit',
                'job_url': "{}/offers/{}".format(self.base_url, offer_data.get('id', '')),
                'posted_date': offer_data.get('published_at', datetime.now().date().isoformat())[:10],
                'requirements': skills
            }
            
            return job
            
        except Exception as e:
            logger.error("Error extracting JustJoin.IT job: {}".format(e))
            return None
    
    def _create_sample_justjoin_jobs(self, query):
        """Create sample jobs for JustJoin.IT"""
        return [
            {
                'title': 'Business Analyst - Banking Platform',
                'company': 'mBank Digital',
                'location': 'Warsaw, Poland (Hybrid)',
                'salary_range': '16,000-22,000 PLN',
                'description': 'Business Analyst role in digital banking team. Work on innovative financial products.',
                'source_platform': 'justjoinit',
                'job_url': 'https://justjoin.it/offers/business-analyst-banking',
                'posted_date': datetime.now().date().isoformat(),
                'requirements': 'Business Analysis, Banking, Digital Products, Agile'
            }
        ]

def get_all_jobs(query="Senior Business Analyst", location="Poland", max_per_source=5):
    """Get jobs from all sources"""
    all_jobs = []
    
    # NoFluffJobs
    try:
        nofluff_scraper = NoFluffJobsScraper()
        nofluff_jobs = nofluff_scraper.search_jobs(query, location, max_per_source)
        all_jobs.extend(nofluff_jobs)
        logger.info("Got {} jobs from NoFluffJobs".format(len(nofluff_jobs)))
    except Exception as e:
        logger.error("NoFluffJobs scraper failed: {}".format(e))
    
    # JustJoin.IT  
    try:
        justjoin_scraper = JustJoinITScraper()
        justjoin_jobs = justjoin_scraper.search_jobs(query, location, max_per_source)
        all_jobs.extend(justjoin_jobs)
        logger.info("Got {} jobs from JustJoin.IT".format(len(justjoin_jobs)))
    except Exception as e:
        logger.error("JustJoin.IT scraper failed: {}".format(e))
    
    return all_jobs

if __name__ == "__main__":
    # Test the scrapers
    logging.basicConfig(level=logging.INFO)
    
    print("Testing job scrapers...")
    jobs = get_all_jobs("Business Analyst", "Poland", 3)
    
    print("\nFound {} total jobs:".format(len(jobs)))
    for job in jobs:
        print("- {} at {} ({})".format(job['title'], job['company'], job['source_platform']))